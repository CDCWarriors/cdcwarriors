{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"MedicalFacilitiesDataCollection.ipynb","provenance":[],"private_outputs":true,"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"view-in-github","colab_type":"text"},"source":["<a href=\"https://colab.research.google.com/github/kaniska/covid-19-hackathon/blob/master/social-network-mining/MedicalEntityRecognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"code","metadata":{"id":"lnEVU3dj4PkT","colab_type":"code","colab":{}},"source":["#library imports"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ArNE3A56cO4l","colab_type":"code","colab":{}},"source":["import tweepy\n","from tweepy import Stream\n","from tweepy import StreamListener \n","from tweepy import OAuthHandler\n","import json"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"aOEr-UFddjdi","colab_type":"code","colab":{}},"source":["consumer_key = \"\"\n","consumer_secret = \"\"\n","access_token = \"\"\n","access_secret = \"\""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GwnQSEH8fjdG","colab_type":"code","colab":{}},"source":["auth = OAuthHandler(consumer_key, consumer_secret)\n","auth.set_access_token(access_token, access_secret)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ywlnUd95fnnX","colab_type":"code","colab":{}},"source":["api = tweepy.API(auth)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8zAjlSWgfprh","colab_type":"code","colab":{}},"source":["@classmethod\n","def parse(cls, api, raw):\n","    status = cls.first_parse(api, raw)\n","    setattr(status, 'json', json.dumps(raw))\n","    return status"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4AccJXVM9ECF","colab_type":"code","colab":{}},"source":["PREFIX = '/content/drive/My Drive/Colab Notebooks/datasets/covid-19-twitter-hack/'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dbCIkJoifufP","colab_type":"code","colab":{}},"source":["# Status() is the data model for a tweet\n","tweepy.models.Status.first_parse = tweepy.models.Status.parse\n","tweepy.models.Status.parse = parse\n","\n","class MyListener(StreamListener):\n"," \n","    def on_data(self, data):\n","        try:\n","            with open(PREFIX + 'tweet_stream.json', 'a') as f:\n","                f.write(data)\n","                return True\n","        except BaseException as e:\n","            print(\"Error on_data: %s\" % str(e))\n","        return True\n"," \n","    def on_error(self, status):\n","        print(status)\n","        return True\n"," "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FAv4QgRigMYa","colab_type":"code","colab":{}},"source":["#Set the hashtag to be searched\n","\n","search_phrases= ['#covid','Drive through testing' , 'N95', 'respirator' , 'Ventilator' , 'sanitizer' , 'surgical face mask' , 'face masks' ]\n","twitter_stream = Stream(auth, MyListener())\n","twitter_stream.filter(track=search_phrases)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"w9zbUqnkgTJP","colab_type":"code","colab":{}},"source":["#view contents of json\n","data = open(PREFIX + 'tweet_stream.json').readlines()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"e1ztjgB0zReU","colab_type":"code","colab":{}},"source":["len(data)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xtfZtC-Lnoun","colab_type":"text"},"source":["Analyze data to see geo data richness of tweets"]},{"cell_type":"code","metadata":{"id":"3lBJFutqny63","colab_type":"code","colab":{}},"source":["def get_geo_data_richness(data):\n","  #Create dictionary to later be stored as JSON. All data will be included\n","  # in the list 'data'\n","  users_with_geodata = {\n","      \"data\": []\n","      }\n","  all_users = []\n","  total_tweets = 0\n","  geo_tweets  = 0\n","\n","  for t in data:\n","    tweet =json.loads(t)\n","    if tweet['user']['id']:\n","      total_tweets+=1\n","      user_id = tweet['user']['id']\n","\n","      if user_id not in all_users:\n","        all_users.append(user_id)\n","\n","        #Give users some data to find them by. User_id listed separately \n","        # to make iterating this data later easier\n","\n","        user_data = {\n","                    \"user_id\" : tweet['user']['id_str'],\n","                    \"features\" : {\n","                        \"name\" : tweet['user']['name'],\n","                        \"id\": tweet['user']['id'],\n","                        \"screen_name\": tweet['user']['screen_name'],\n","                        \"tweets\" : 1,\n","                        \"location\": tweet['user']['location'],\n","                    }\n","                }\n","        #Iterate through different types of geodata to get the variable primary_geo\n","        if tweet['coordinates']:\n","          user_data[\"features\"][\"primary_geo\"] = str(tweet['coordinates']['coordinates'][0]) + \", \" + str(tweet['coordinates']['coordinates'][1])\n","          user_data[\"features\"][\"geo_type\"] = \"Tweet coordinates\"\n","        elif tweet['place']:\n","          user_data[\"features\"][\"primary_geo\"] = tweet['place']['full_name'] + \", \" + tweet['place']['country']\n","          user_data[\"features\"][\"geo_type\"] = \"Tweet place\"\n","        else:\n","          user_data[\"features\"][\"primary_geo\"] = tweet['user']['location']\n","          user_data[\"features\"][\"geo_type\"] = \"User location\"\n","        \n","        #Add only tweets with some geo data to .json\n","        if user_data[\"features\"][\"primary_geo\"]:\n","          users_with_geodata['data'].append(user_data)\n","          geo_tweets += 1\n","          total_tweets +=1\n","    \n","    #If user already listed, increase their tweet count\n","    elif user_id in all_users:\n","      for user in users_with_geodata[\"data\"]:\n","        if user_id == user[\"user_id\"]:\n","          user[\"features\"][\"tweets\"] += 1\n","\n","  #Count the total amount of tweets for those users that had geodata            \n","  for user in users_with_geodata[\"data\"]:\n","      geo_tweets = geo_tweets + user[\"features\"][\"tweets\"]\n","\n","\n","\n","  #Get some aggregated numbers on the data\n","  print(\"The file included \" + str(len(all_users)) + \" unique users who tweeted with or without geo data\")\n","  print(\"The file included \" + str(len(users_with_geodata['data'])) + \" unique users who tweeted with geo data, including 'location'\")\n","  print(\"The users with geo data tweeted \" + str(geo_tweets) + \" out of the total \" + str(total_tweets) + \" of tweets.\")\n","  \n","  # Save data to JSON file\n","  with open(PREFIX + 'tweet_users_geo.json', 'w') as fout:\n","    fout.write(json.dumps(users_with_geodata, indent=4))\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FWHLJkIq3PeT","colab_type":"code","colab":{}},"source":["get_geo_data_richness(data)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qEi9_w3K90gC","colab_type":"text"},"source":["## Todo\n","- Use openrefine to convert tweet_users_geo.json to csv\n","- Upload csv to Google Fusion Tables and tag location column for display."]},{"cell_type":"code","metadata":{"id":"bL8VCPUF-3Cl","colab_type":"code","colab":{}},"source":["!git status"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WlSpI69R--6-","colab_type":"code","colab":{}},"source":["!git add social-network-mining/MedicalFacilitiesDataCollection.ipynb"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wFIQrkMZ_IsE","colab_type":"code","colab":{}},"source":["!git commit -m 'Crawl tweets based on medical kits & medical facilities terms'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ez-S2aaK_yQ-","colab_type":"code","colab":{}},"source":["!git push origin davies/medical-facilities-geodata"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jCXKeNV1_7_c","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}